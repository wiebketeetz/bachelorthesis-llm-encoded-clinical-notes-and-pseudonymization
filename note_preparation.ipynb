{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ad6f8-9e58-47e7-bb4d-132fea34ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31324b-b4bc-403e-b910-48fb9dd228cf",
   "metadata": {},
   "source": [
    "## Load notes\n",
    "- put the notes in a dict with the file name  as the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817b053-e351-4ca3-9f84-58eec889506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = Path('annotated') \n",
    "note_names = list(directory.glob(\"*.txt\"))\n",
    "\n",
    "notes = {}\n",
    "\n",
    "for filename in note_names:\n",
    "    key = str(filename).replace('annotated/','').replace('.annotated.txt', '')\n",
    "    with open(filename) as file:\n",
    "        text = file.read()\n",
    "    notes[key] = text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5023a42-052a-4a67-998d-d8c71f81256e",
   "metadata": {},
   "source": [
    "## Ensure uniform beginning of every note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e15a17-d656-4dfa-9580-ce8ce50a83d1",
   "metadata": {},
   "source": [
    "#### Load template for the beginning of every note \n",
    "- by gender\n",
    "- with added label for address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004093f-7dbf-446f-ad1e-da0b54618332",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('note_template/note_start_template_M.txt') as file:\n",
    "        template_M = file.read()\n",
    "    \n",
    "with open('note_template/note_start_template_F.txt') as file:\n",
    "        template_F = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b0420-6a8c-49ee-8037-1eade8ed3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(template_F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802b469e-cc83-4bda-af37-032c0a2d0a32",
   "metadata": {},
   "source": [
    "#### Replace the beginning of each note with the according template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7b039-ecc6-4c20-a1d4-94c233b9b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in notes:\n",
    "    \n",
    "    if key.startswith('F'):\n",
    "        notes[key] = re.sub(r'^(.*)</sex>', template_F, notes[key], flags = re.DOTALL)\n",
    "        \n",
    "    else: #key starts with M:\n",
    "        notes[key] = re.sub(r'^(.*)</sex>', template_M, notes[key], flags = re.DOTALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e7267-c4e7-4ae8-96e3-c7c68ecfa619",
   "metadata": {},
   "source": [
    "## Error handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d5498-06fe-4136-a64e-844d70dd1275",
   "metadata": {},
   "source": [
    "#### Functions for handling some misplaced labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23666f0-37e2-46a6-aa8d-a6156ec39174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes name-label from everything that isn't anonymized (and therefore not a name)\n",
    "\n",
    "name_search_mask = '(<name>)([^<]*)(</name>)'\n",
    "\n",
    "def name_check(match):\n",
    "    \n",
    "    alledged_name = match.group(2)\n",
    "    \n",
    "    if alledged_name == '___':\n",
    "        return '<name>___</name>'\n",
    "    else:\n",
    "        return alledged_name\n",
    "\n",
    "\n",
    "\n",
    "# removes pronoun-label from everything that isn't a 3rd person pronoun\n",
    "\n",
    "pronoun_search_mask = '(<pronoun_[^>]*>)([^<]*)(</pronoun_[^>]*>)'\n",
    "\n",
    "def pronoun_check(match):\n",
    "\n",
    "    alledged_pronoun = match.group(2)\n",
    "    \n",
    "    if alledged_pronoun in ['she', 'her', 'herself', 'he', 'his', 'him', 'himself']:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return alledged_pronoun \n",
    "\n",
    "\n",
    "\n",
    "# removes forms of 'year-old' after age label for grammatical correctness\n",
    "\n",
    "#options \n",
    "yo = 'year old|year-old|years old|yo|y/o|y.o'\n",
    "\n",
    "age_search_mask = f'(<age>[^<]*</age> )({yo})'\n",
    "\n",
    "#returns only the age-label\n",
    "def delete_yo(match):\n",
    "    return match.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b660941-9e00-4a06-8c0b-852089aed131",
   "metadata": {},
   "source": [
    "#### Loop through all notes and handle possible errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fd066-6cec-44cb-b734-299f6298191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in notes:\n",
    "    notes[key] = re.sub(name_search_mask,name_check, notes[key])\n",
    "    notes[key] = re.sub(pronoun_search_mask, pronoun_check, notes[key], flags = re.IGNORECASE)\n",
    "    notes[key] = re.sub(age_search_mask, delete_yo, notes[key], flags = re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b391dda-3715-4da8-a711-e6fb9063e7c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for key in notes:\n",
    "#    print(key)\n",
    "#    print(notes[key][:400])\n",
    "#    print('-------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57124bda-21bf-43f2-b99a-c87765ed2728",
   "metadata": {},
   "source": [
    "## Load sampled_data_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8eef6-92a7-415b-b2a9-a5c41fdc9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_csv('demographics/sampled_data_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8afaf4-c148-4a90-9e0e-1c0b8bae9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a5835-d9ef-4ef2-9bb2-9230a1af03a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_info = demographics[['abbrev', 'hadm_id','name', 'address', 'race', 'gender', 'dob', 'actual_age', \n",
    "                          'admittime_today', 'dischtime_today', 'thirty_day_readmission']].copy()\n",
    "note_info.loc[:, 'filename'] =  note_info.loc[:, 'abbrev'].astype(str) + '_' + note_info.loc[:, 'hadm_id'].astype(str)\n",
    "note_info.loc[:, 'race_abbrev'] =  note_info.loc[:, 'abbrev'].apply(lambda x: x[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f15577-f567-4ce7-9c6f-55920b0cc00b",
   "metadata": {},
   "source": [
    "## Functions for adding and removing baseline personal info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adfa17-6cdf-455f-993d-071192113dcb",
   "metadata": {},
   "source": [
    "#### Add race info for every note\n",
    "- precondition: call before the start of the note is changed (before adding in personal information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984cbe7-7a76-460b-a1ea-70be5577d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_race(notes):\n",
    "\n",
    "    for key in notes:\n",
    "\n",
    "        hadm_id = re.sub('[^2]*_', '', key)\n",
    "        race = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'race'].iloc[0]\n",
    "        notes[key] = (notes[key][:len(template_F)+1] + 'race: <race>' + str(race) + '</race>' + notes[key][len(template_F)+1:])\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad0d882-1252-44dd-9184-f23c17a0f098",
   "metadata": {},
   "source": [
    "#### Add age info for every note\n",
    "- precondition: call before the start of the note is changed (before adding in personal information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5127ef-d47b-4523-960e-e3f9308c0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_age(notes):\n",
    "\n",
    "    for key in notes:\n",
    "\n",
    "        hadm_id = re.sub('[^2]*_', '', key)\n",
    "        age = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'actual_age'].iloc[0]\n",
    "        notes[key] = (notes[key][:len(template_F)+1] + 'age: <age>' + str(age) + '</age>' + notes[key][len(template_F)+1:])\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0cf1d6-d5ba-4638-b9ef-59c79d5db460",
   "metadata": {},
   "source": [
    "#### Swap baseline personal information in and out\n",
    "- takes information from note_info and puts it into the note if the according parameter is set to True\n",
    "- otherwise anonymizes this personal info in the note\n",
    "- neutralize gendered terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b49e8-250e-438f-a780-6bc20b4432bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_in(notes, name =  True, address = True, age = True, visitdates = True, gender = True, race = True):\n",
    "\n",
    "    for key in notes:\n",
    "        \n",
    "        hadm_id = re.sub('[^2]*_', '', key)\n",
    "\n",
    "        if name:\n",
    "            name = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'name'].iloc[0]\n",
    "            name = '<name>' + str(name) + '</name>'\n",
    "        \n",
    "            notes[key] = re.sub('<name>[^<]*</name>', name, notes[key])\n",
    "            \n",
    "        if not name:\n",
    "            notes[key] = re.sub('<name>[^<]*</name>', '<name>___</name>', notes[key])\n",
    "\n",
    "        \n",
    "        if address:\n",
    "            address = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'address'].iloc[0]\n",
    "            address = '<address>' + str(address) + '</address>'\n",
    "            notes[key] = re.sub('<address>[^<]*</address>', address, notes[key])\n",
    "            \n",
    "        if not address:\n",
    "            notes[key] = re.sub('<address>[^<]*</address>', '<address>___</address>', notes[key])\n",
    "\n",
    "        \n",
    "        if age:\n",
    "            actual_age = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'actual_age'].iloc[0]\n",
    "            actual_age = '<age>' + str(actual_age) + ' year-old ' + '</age>'\n",
    "            notes[key] = re.sub('<age>[^<]*</age>', actual_age, notes[key])\n",
    "\n",
    "        if not age:\n",
    "            notes[key] = re.sub('<age>[^<]*</age>', '<age>___</age>', notes[key])\n",
    "\n",
    "        \n",
    "        if visitdates:\n",
    "            admittime_today = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'admittime_today'].iloc[0]\n",
    "            admittime_today = '<admission_date>' + str(admittime_today) + '</admission_date>'\n",
    "            notes[key] = re.sub('<admission_date>[^<]*</admission_date>', str(admittime_today), notes[key])\n",
    "            \n",
    "            dischtime_today = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'dischtime_today'].iloc[0]\n",
    "            dischtime_today = '<discharge_date>' + str(dischtime_today) + '</discharge_date>'\n",
    "            notes[key] = re.sub('<discharge_date>[^<]*</discharge_date>', str(dischtime_today), notes[key])\n",
    "\n",
    "        if not visitdates:\n",
    "            notes[key] = re.sub('<admission_date>[^<]*</admission_date>', '<admission_date>___</admission_date>', notes[key])\n",
    "            notes[key] = re.sub('<discharge_date>[^<]*</discharge_date>', '<discharge_date>___</discharge_date>', notes[key])\n",
    "\n",
    "        \n",
    "        if age and visitdates:\n",
    "            dob = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'dob'].iloc[0]\n",
    "            dob = '<dob>' + str(dob) + '</dob>'\n",
    "            notes[key] = re.sub('<dob>[^<]*</dob>', dob, notes[key])\n",
    "\n",
    "        if not (age and visitdates):\n",
    "            notes[key] = re.sub('<dob>[^<]*</dob>', '<dob>___</dob>', notes[key])\n",
    "\n",
    "        \n",
    "        if gender:\n",
    "            gender = key[0] \n",
    "                \n",
    "            if gender == 'F':\n",
    "                notes[key] = re.sub('<sex>[^<]*</sex>', '<sex>F</sex>', notes[key])\n",
    "                notes[key] = re.sub('<pronoun_subject>[^<]*</pronoun_subject>', '<pronoun_subject>she</pronoun_subject>', notes[key])\n",
    "                notes[key] = re.sub('<pronoun_object>[^<]*</pronoun_object>', '<pronoun_object>her</pronoun_object>', notes[key])\n",
    "                notes[key] = re.sub('<pronoun_possessive>[^<]*</pronoun_possessive>', '<pronoun_possessive>her</pronoun_possessive>', notes[key])\n",
    "                notes[key] = re.sub('<pronoun_reflexive>[^<]*</pronoun_reflexive>', '<pronoun_reflexive>herself</pronoun_reflexive>', notes[key])\n",
    "                notes[key] = re.sub('<form_of_address>[^<]*</form_of_address>', '<form_of_address>Ms.</form_of_address>', notes[key])\n",
    "                notes[key] = re.sub('<gendered_noun>[^<]*</gendered_noun>', '<gendered_noun>woman</gendered_noun>', notes[key])\n",
    "            else:\n",
    "                notes[key] = re.sub('<sex>[^<]*</sex>', '<sex>M</sex>', notes[key])\n",
    "                notes[key] = re.sub('<pronoun_subject>[^<]*</pronoun_subject>', '<pronoun_subject>he</pronoun_subject>', notes[key])\n",
    "                notes[key] = re.sub('<pronoun_object>[^<]*</pronoun_object>', '<pronoun_object>him</pronoun_object>', notes[key])\n",
    "                notes[key] = re.sub('<pronoun_possessive>[^<]*</pronoun_possessive>', '<pronoun_possessive>his</pronoun_possessive>', notes[key])\n",
    "                notes[key] = re.sub('<pronoun_reflexive>[^<]*</pronoun_reflexive>', '<pronoun_reflexive>himself</pronoun_reflexive>', notes[key])\n",
    "                notes[key] = re.sub('<form_of_address>[^<]*</form_of_address>', '<form_of_address>Mr.</form_of_address>', notes[key])\n",
    "                notes[key] = re.sub('<gendered_noun>[^<]*</gendered_noun>', '<gendered_noun>man</gendered_noun>', notes[key])\n",
    "        \n",
    "        if not gender:\n",
    "            notes[key] = re.sub('<sex>[^<]*</sex>', '<sex>___</sex>', notes[key])\n",
    "            notes[key] = re.sub('<pronoun_subject>[^<]*</pronoun_subject>', '<pronoun_subject>the patient</pronoun_subject>', notes[key])\n",
    "            notes[key] = re.sub('<pronoun_object>[^<]*</pronoun_object>', '<pronoun_object>the patient</pronoun_object>', notes[key])\n",
    "            notes[key] = re.sub('<pronoun_possessive>[^<]*</pronoun_possessive>', '<pronoun_possessive>the patient\\'s</pronoun_possessive>', notes[key])\n",
    "            notes[key] = re.sub('<pronoun_reflexive>[^<]*</pronoun_reflexive>', '<pronoun_reflexive>the patient</pronoun_reflexive>', notes[key])\n",
    "            notes[key] = re.sub('<form_of_address>[^<]*</form_of_address>', '<form_of_address>___</form_of_address>', notes[key])\n",
    "            notes[key] = re.sub('<gendered_noun>[^<]*</gendered_noun>', '<gendered_noun>___</gendered_noun>', notes[key])\n",
    "\n",
    "\n",
    "        if race:\n",
    "            race = note_info.loc[note_info['hadm_id'] == int(hadm_id), 'race'].iloc[0]\n",
    "            race = '<race>' + str(race) + '</race>'\n",
    "            notes[key] = re.sub('<race>[^<]*</race>', race, notes[key]) \n",
    "\n",
    "        if not race:\n",
    "            notes[key] = re.sub('<race>[^<]*</race>', '<race>___</race>', notes[key])\n",
    "    \n",
    "    return notes\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda57ab-b0c4-455c-b1d1-524f126db740",
   "metadata": {},
   "source": [
    "#### Functions for adding a specific info into a text note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffff0a6-0555-4478-b4a1-a209ffa6019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_name(text, name):\n",
    "    \n",
    "    name = '<name>' + str(name) + '</name>'\n",
    "    text = re.sub('<name>[^<]*</name>', name, text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f151b-2121-4dc6-a980-4ec897e2de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_address(text, address):\n",
    "    \n",
    "    address = '<address>' + str(address) + '</address>'\n",
    "    text = re.sub('<address>[^<]*</address>', address, text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217bcaaa-e1a8-43ba-8cf9-1aa0fb12d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_age(text, age, dob):\n",
    "        \n",
    "    age = '<age>' + str(age) + '</age>'\n",
    "    dob = '<dob>' + str(dob) + '</dob>'\n",
    "    text = re.sub('<age>[^<]*</age>', age, text)\n",
    "    text = re.sub('<dob>[^<]*</dob>', dob, text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4887f-51df-4d37-a496-7cfbff0391a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_map = {\n",
    "    'AIAN'   : 'AMERICAN INDIAN/ALASKA NATIVE',\n",
    "    'AS'     : 'ASIAN',\n",
    "    'AS_AI'  : 'ASIAN - ASIAN INDIAN',\n",
    "    'AS_CH'  : 'ASIAN - CHINESE',\n",
    "    'AS_SEA' : 'ASIAN - SOUTH EAST ASIAN',\n",
    "    'BL_A'   : 'BLACK/AFRICAN',\n",
    "    'BL_AA'  : 'BLACK/AFRICAN AMERICAN',\n",
    "    'BL_CV'  : 'BLACK/CAPE VERDEAN',\n",
    "    'BL_CI'  : 'BLACK/CARIBBEAN ISLAND',\n",
    "    'HL'     : 'HISPANIC OR LATINO',\n",
    "    'HL_CO'  : 'HISPANIC/LATINO - COLUMBIAN',\n",
    "    'HL_DO'  : 'HISPANIC/LATINO - DOMINICAN',\n",
    "    'HL_GU'  : 'HISPANIC/LATINO - GUATEMALAN',\n",
    "    'HL_PR'  : 'HISPANIC/LATINO - PUERTO RICAN',\n",
    "    'HL_SA'  : 'HISPANIC/LATINO - SALVADORAN',\n",
    "    'PT'     : 'PORTUGUESE',\n",
    "    'W'      : 'WHITE',\n",
    "    'W_BR'   : 'WHITE - BRAZILIAN',\n",
    "    'W_EE'   : 'WHITE - EASTERN EUROPEAN',\n",
    "    'W_OE'   : 'WHITE - OTHER EUROPEAN',\n",
    "    'W_RU'   : 'WHITE - RUSSIAN',\n",
    "}\n",
    "\n",
    "def swap_race(text, race):\n",
    "\n",
    "    race = '<race>' + race_map[race] + '</race>'\n",
    "    text = re.sub('<race>[^<]*</race>', race, text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c89aa6b-f25e-4633-851a-13c892bac52a",
   "metadata": {},
   "source": [
    "## Function for removing labels (last step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a6fa5-ee2b-4e6f-9354-e80e07708a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_labels(notes):\n",
    "    for key in notes:\n",
    "        notes[key] = re.sub('<[^>]*>', '', notes[key])\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb589a03-4e29-444d-94b3-5dc073e804e1",
   "metadata": {},
   "source": [
    "## Turn notes into DataFrame with hadm_id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a17b74-ca7f-427b-9bd6-0c8847fa2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hadm_id(new_notes):\n",
    "    \n",
    "    notes_df = pd.DataFrame.from_dict(new_notes, orient = 'index', columns = ['text'])\n",
    "    notes_df = notes_df.reset_index(names = 'hadm_id')\n",
    "    notes_df['hadm_id'] = notes_df['hadm_id'].apply(lambda x: int(re.sub('[^2]*_', '', x)))\n",
    "\n",
    "    return notes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0475be21-d326-44bb-9be9-a4b0aa3d797f",
   "metadata": {},
   "source": [
    "## Create train/test splits by race-gender subgroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d44761-8d79-4f97-9fa7-4d220d3822ed",
   "metadata": {},
   "source": [
    "rename columns to 'text' and 'thirty_day_readmission' (if needed)\n",
    "- e.g. from more specific column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc1214-7cd4-4cc5-97d5-e3a12c2d42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_col_t_r(df):\n",
    "    \n",
    "    df.columns = ['text', 'thirty_day_readmission']\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7ae100-5e6c-4d0a-b858-9880dbe1f8fd",
   "metadata": {},
   "source": [
    "#### Create splits directly on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852d64c-7850-4d9e-a058-86c1a11c78a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadm_order = get_hadm_id(notes.copy())\n",
    "hadm_order['hadm_index'] = hadm_order.index\n",
    "hadm_order = hadm_order[['hadm_index', 'hadm_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3e290-dab0-447c-a67b-95fea3893656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits(new_notes, eval_target = 'thirty_day_readmission', main_attribute = 'text'):\n",
    "\n",
    "    if type(new_notes) == dict:\n",
    "        #Put the notes into a DataFrame and add their hadm_id as a column\n",
    "        notes_df = get_hadm_id(new_notes)\n",
    "\n",
    "        \n",
    "    elif type(new_notes) == pd.DataFrame:\n",
    "        if main_attribute != 'hadm_id':\n",
    "            notes_df = new_notes[[f'{main_attribute}', 'hadm_id']]\n",
    "        else:\n",
    "            notes_df = new_notes['hadm_id']\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise TypeError('Note Input has to be a dictionary or pandas DataFrame')\n",
    "\n",
    "    \n",
    "    #sort into original order of notes to ensure reproducibility\n",
    "    notes_df = pd.merge(notes_df, hadm_order, on = 'hadm_id', how = 'inner')\n",
    "    notes_df = notes_df.sort_values(by = 'hadm_index')\n",
    "    notes_df.drop('hadm_index', axis = 1, inplace = True)\n",
    "    \n",
    "    #Get info about evaluation target (e.g. 30-day-readmission) and gender-race subgroup\n",
    "    if eval_target == 'thirty_day_readmission': \n",
    "        notes_df = pd.merge(notes_df, note_info[['hadm_id', f'{eval_target}', 'abbrev']], on = 'hadm_id')\n",
    "    else:\n",
    "        notes_df = pd.merge(notes_df, note_info[['hadm_id', f'{eval_target}', 'abbrev', 'thirty_day_readmission']], on = 'hadm_id')\n",
    "    notes_df = notes_df.groupby('abbrev')\n",
    "\n",
    "    #Split into train and test group by subgroup\n",
    "    first_group = list(notes_df.groups)[0]\n",
    "    subgroup = notes_df.get_group(first_group)\n",
    "\n",
    "    X = subgroup[f'{main_attribute}']\n",
    "    y = subgroup[f'{eval_target}']\n",
    "    strat = subgroup['thirty_day_readmission']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify = strat)\n",
    "\n",
    "    for abbrev in notes_df.groups:\n",
    "    \n",
    "        if abbrev != first_group:\n",
    "        \n",
    "            subgroup = notes_df.get_group(abbrev)\n",
    " \n",
    "            X = subgroup[f'{main_attribute}']\n",
    "            y = subgroup[f'{eval_target}']\n",
    "            strat = subgroup['thirty_day_readmission']\n",
    "            \n",
    "            this_X_train, this_X_test, this_y_train, this_y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify = strat)\n",
    "\n",
    "            X_train = pd.concat([X_train, this_X_train])\n",
    "            X_test = pd.concat([X_test, this_X_test])\n",
    "            y_train = pd.concat([y_train, this_y_train])\n",
    "            y_test = pd.concat([y_test, this_y_test]) \n",
    "    \n",
    "    train = pd.concat([X_train, y_train], axis = 1)  \n",
    "    test = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f20f0d5-eb14-437c-86c4-f27a33d7569f",
   "metadata": {},
   "source": [
    "#### extract hadm_id identifiers of different splits\n",
    "- used when information is swapped between the notes\n",
    "- (swapping only between notes in the test group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953090f4-0b91-4613-99b5-16116a24d6a7",
   "metadata": {},
   "source": [
    "##### Compute the prevalence of true thirty_day_readmission in the train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb5a39-1d5a-4c65-9345-3a7824c3d376",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_df = notes.copy()\n",
    "\n",
    "train,test = create_splits(notes_df, eval_target = 'thirty_day_readmission', main_attribute = 'hadm_id')\n",
    "\n",
    "train['split'] = 'train'\n",
    "test['split'] = 'test'\n",
    "\n",
    "prevalence = pd.concat([train, test], axis = 0)\n",
    "prevalence.to_csv('prevalence/prevalence_by_hadm_id_strat.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c9987b-f6df-43c2-8bd9-affe5ec7bf10",
   "metadata": {},
   "source": [
    "##### create separate data structures for the test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea48e98-8465-4abc-babc-b238ccceecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by split\n",
    "test_df = prevalence[prevalence['split'] == 'test'].drop('split', axis = 1)\n",
    "train_df = prevalence[prevalence['split'] == 'train'].drop('split', axis = 1)\n",
    "\n",
    "#split note_info by split group\n",
    "note_info_test = pd.merge(test_df, note_info, how = 'inner')\n",
    "note_info_train = pd.merge(train_df, note_info, how = 'inner')\n",
    "\n",
    "test_notes = {}\n",
    "\n",
    "for key in notes:\n",
    "\n",
    "    hadm_id = int(re.sub('[^2]*_', '', key))\n",
    "\n",
    "    if hadm_id in list(test_df['hadm_id']):\n",
    "        test_notes[key] = notes[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec13d39-7ea7-44a2-b429-48c95048a73d",
   "metadata": {},
   "source": [
    "##### (additional: compute prevalence in each group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636b89d-8769-4d05-a699-f384b4d27c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_info = pd.merge(note_info, prevalence, on = ['hadm_id', 'thirty_day_readmission'])\n",
    "prev_info = prev_info[['thirty_day_readmission', 'split', 'gender', 'race_abbrev', 'actual_age']]\n",
    "\n",
    "prev_df = []\n",
    "\n",
    "genders = ['F', 'M']\n",
    "\n",
    "for gender in genders:\n",
    "    \n",
    "    subset = prev_info[prev_info['gender'] == gender]\n",
    "    \n",
    "    train_df = subset[subset['split'] == 'train']\n",
    "    test_df = subset[subset['split'] == 'test']\n",
    "    \n",
    "    train_prev = train_df['thirty_day_readmission'].value_counts(normalize = True)\n",
    "    train_prev = train_prev.get(True)\n",
    "    test_prev = test_df['thirty_day_readmission'].value_counts(normalize = True)\n",
    "    test_prev = test_prev.get(True)\n",
    "\n",
    "    prev_df.append({'category': gender, 'train_prevalence': train_prev, 'test_prevalence': test_prev})\n",
    "\n",
    "\n",
    "races = note_info['race_abbrev'].unique()\n",
    "\n",
    "for race in races:\n",
    "    \n",
    "    subset = prev_info[prev_info['race_abbrev'] == race]\n",
    "    \n",
    "    train_df = subset[subset['split'] == 'train']\n",
    "    test_df = subset[subset['split'] == 'test']\n",
    "    \n",
    "    train_prev = train_df['thirty_day_readmission'].value_counts(normalize = True)\n",
    "    train_prev = train_prev.get(True)\n",
    "    test_prev = test_df['thirty_day_readmission'].value_counts(normalize = True)\n",
    "    test_prev = test_prev.get(True)\n",
    "\n",
    "    prev_df.append({'category': race, 'train_prevalence': train_prev, 'test_prevalence': test_prev})\n",
    "\n",
    "age_range = [(19,29),(30,39),(40,49),(50,59),(60,69),(70,79),(80,89),(90,98), (19,50), (74,96)]\n",
    "\n",
    "for (young, old) in age_range:\n",
    "    \n",
    "    subset = prev_info[(prev_info['actual_age'] >= young) & (prev_info['actual_age'] <= old)]\n",
    "    \n",
    "    train_df = subset[subset['split'] == 'train']\n",
    "    test_df = subset[subset['split'] == 'test']\n",
    "    \n",
    "    train_prev = train_df['thirty_day_readmission'].value_counts(normalize = True)\n",
    "    train_prev = train_prev.get(True)\n",
    "    test_prev = test_df['thirty_day_readmission'].value_counts(normalize = True)\n",
    "    test_prev = test_prev.get(True)\n",
    "\n",
    "    prev_df.append({'category': str((young, old)), 'train_prevalence': train_prev, 'test_prevalence': test_prev})\n",
    "\n",
    "prev_df.to_csv('prevalence/prevalence_by_group.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13d6dd-c8b6-4904-8eb5-d38fea4aa076",
   "metadata": {},
   "source": [
    "## Create notes with combination of personal information for readmission evaluation\n",
    "- /grouped_anonymized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5b261c-0481-4496-a068-8e0084e27d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anonymization_stages = {}\n",
    "\n",
    "#Compute all possible combinations of personal info\n",
    "possible_combinations = list(itertools.product([True, False], repeat = 6))\n",
    "attributes = ['name', 'address', 'age', 'visitdates', 'gender', 'race']\n",
    "\n",
    "for combo in possible_combinations:\n",
    "\n",
    "    #put the personal infos together into one key\n",
    "    key = '_'\n",
    "    for i in range(6):\n",
    "        if combo[i]:\n",
    "            key += attributes[i]\n",
    "            key += '_'\n",
    "\n",
    "    #Swap personal info in/out as needed\n",
    "    new_notes = notes.copy()\n",
    "    new_notes = swap_in(new_notes, *combo)\n",
    "    new_notes = remove_labels(new_notes)\n",
    "\n",
    "    train, test = create_splits(new_notes, eval_target = 'thirty_day_readmission')\n",
    "\n",
    "    path = f'readmission_prediction/data/{key}'\n",
    "    if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    train.to_csv(f'readmission_prediction/data/{key}/train.csv', index = False)\n",
    "    test.to_csv(f'readmission_prediction/data/{key}/test.csv', index = False)    \n",
    "    \n",
    "    #anonymization_stages[key] = new_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aba7dbb-fe3b-4058-8c79-f7b9655a6b64",
   "metadata": {},
   "source": [
    "## Create notes for race, gender and age evaluation (/embedding_significance)\n",
    "- info not given directly\n",
    "  - every other possible info is given\n",
    "  - note is anonymized as much as possible \n",
    "- info given directly\n",
    "  - every other possible info is given\n",
    "  - note is anonymized as much as possible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ddcda-2299-4b2b-a49a-80c55fb07a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_combinations = list(itertools.product(['given','no'], ['race', 'gender', 'age'], ['everything', 'nothing']))\n",
    "\n",
    "dir_names = []\n",
    "\n",
    "for combo in possible_combinations:\n",
    "\n",
    "    dir_name = '_'.join(combo)\n",
    "    dir_names.append(dir_name)\n",
    "\n",
    "    new_notes = notes.copy()\n",
    "    \n",
    "    if combo[2] == 'everything':\n",
    "\n",
    "        if combo[0] == 'no':\n",
    "\n",
    "            if combo[1] == 'race':\n",
    "                new_notes = swap_in(new_notes, race = False)\n",
    "            \n",
    "            if combo[1] == 'gender':\n",
    "                new_notes = swap_in(new_notes, gender = False)\n",
    "\n",
    "            if combo[1] == 'age':\n",
    "                new_notes = swap_in(new_notes, age = False)\n",
    "\n",
    "        else: # combo[0] == 'given'\n",
    "\n",
    "            if combo[1] == 'race':\n",
    "                new_notes = add_race(new_notes)\n",
    "\n",
    "            if combo[1] == 'age':\n",
    "                new_notes = add_age(new_notes)\n",
    "                \n",
    "            new_notes = swap_in(new_notes)\n",
    "            \n",
    "    \n",
    "    else: # combo[2] == 'nothing'\n",
    "\n",
    "        if combo[0] == 'given':\n",
    "\n",
    "            if combo[1] == 'race':\n",
    "                new_notes = add_race(new_notes)\n",
    "                new_notes = swap_in(new_notes, name =  False, address = False, age = False, visitdates = False, gender = False, race = True)\n",
    "            \n",
    "            if combo[1] == 'gender':\n",
    "                new_notes = swap_in(new_notes, name =  False, address = False, age = False, visitdates = False, gender = True, race = False)\n",
    "\n",
    "            if combo[1] == 'age':\n",
    "                new_notes = add_age(new_notes)\n",
    "                new_notes = swap_in(new_notes, name =  False, address = False, age = True, visitdates = False, gender = False, race = False)\n",
    "\n",
    "        else: # combo[0] == 'no'\n",
    "\n",
    "            new_notes = swap_in(new_notes, name =  False, address = False, age = False, visitdates = False, gender = False, race = False)\n",
    "\n",
    "    new_notes = remove_labels(new_notes)\n",
    "    \n",
    "    #Export notes\n",
    "    if combo[1] == 'race':\n",
    "        \n",
    "        train, test = create_splits(new_notes, eval_target = 'race')\n",
    "        path = f'attribute_prediction/race/data/{dir_name}'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        train.to_csv(f'{path}/train.csv', index = False)\n",
    "        test.to_csv(f'{path}/test.csv', index = False)\n",
    "\n",
    "    if combo[1] == 'gender':\n",
    "        \n",
    "        train, test = create_splits(new_notes, eval_target = 'gender')\n",
    "        path = f'attribute_prediction/gender/data/{dir_name}'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        train.to_csv(f'{path}/train.csv', index = False)\n",
    "        test.to_csv(f'{path}/test.csv', index = False)\n",
    "\n",
    "    if combo[1] == 'age':\n",
    "\n",
    "        train, test = create_splits(new_notes, eval_target = 'actual_age')\n",
    "        path = f'attribute_prediction/age/data/{dir_name}'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        train.to_csv(f'{path}/train.csv', index = False)\n",
    "        test.to_csv(f'{path}/test.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5304a-bc7e-4918-aa3e-a780c8f09a78",
   "metadata": {},
   "source": [
    "## Notes with different gender (/grouped_anonymized/gender_swapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d154c-ed0a-47d7-baab-d8e9fcb10b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_notes = test_notes.copy()\n",
    "\n",
    "f = {}\n",
    "f_m = {}\n",
    "m = {}\n",
    "m_f = {}\n",
    "\n",
    "#split notes into male and female\n",
    "for key in new_notes:\n",
    "\n",
    "    if key.startswith('F'):\n",
    "        #exclude race that doesnt have a male subgroup\n",
    "        if not key.startswith('F_HL_CO'):\n",
    "            f[key] = new_notes[key] \n",
    "            f_m[f'M{key[1:]}'] = new_notes[key]\n",
    "    else:\n",
    "        m[key] = new_notes[key] \n",
    "        m_f[f'F{key[1:]}'] = new_notes[key]\n",
    "            \n",
    "#prepare the notes\n",
    "f = swap_in(f)\n",
    "f_m = swap_in(f_m)\n",
    "m = swap_in(m)\n",
    "m_f = swap_in(m_f)\n",
    "\n",
    "# get hadm_id for each note, put out a df\n",
    "f = get_hadm_id(f)\n",
    "f_m = get_hadm_id(f_m)\n",
    "m = get_hadm_id(m)\n",
    "m_f = get_hadm_id(m_f)\n",
    "\n",
    "#get additional info about notes\n",
    "#put notes back together by gender\n",
    "f = pd.merge(f, note_info[['hadm_id', 'race', 'name', 'address', 'actual_age', 'thirty_day_readmission']], how = 'inner', on = 'hadm_id')\n",
    "f_complete = pd.merge(f, f_m, how = 'inner', on = 'hadm_id', suffixes = ['_f', '_f_m'])\n",
    "m = pd.merge(m, note_info[['hadm_id', 'race', 'name', 'address', 'actual_age', 'thirty_day_readmission']], how = 'inner', on = 'hadm_id')\n",
    "m_complete = pd.merge(m, m_f, how = 'inner', on = 'hadm_id', suffixes = ['_m', '_m_f'])\n",
    "\n",
    "#add age_rank for each race\n",
    "f_complete['age_rank'] = f_complete.groupby('race')['actual_age'].transform(lambda x: x.rank(method = 'first'))\n",
    "m_complete['age_rank'] = m_complete.groupby('race')['actual_age'].transform(lambda x: x.rank(method = 'first'))\n",
    "\n",
    "#merge genders together by race and age_rank\n",
    "df = pd.merge(f_complete, m_complete, on = ['race', 'age_rank'], suffixes = ['_f', '_m'], validate = 'one_to_one')\n",
    "\n",
    "#swap names\n",
    "df['text_n_f'] = df.apply(lambda x: swap_name(x['text_f'], x['name_m']), axis = 1)\n",
    "df['text_n_m'] = df.apply(lambda x: swap_name(x['text_m'], x['name_f']), axis = 1)\n",
    "df['text_n_gender_f'] = df.apply(lambda x: swap_name(x['text_f_m'], x['name_m']), axis = 1)\n",
    "df['text_n_gender_m'] = df.apply(lambda x: swap_name(x['text_m_f'], x['name_f']), axis = 1)\n",
    "#swap address\n",
    "df['text_a_f'] = df.apply(lambda x: swap_address(x['text_f'], x['address_m']), axis = 1)\n",
    "df['text_a_m'] = df.apply(lambda x: swap_address(x['text_m'], x['address_f']), axis = 1)\n",
    "df['text_a_gender_f'] = df.apply(lambda x: swap_address(x['text_f_m'], x['address_m']), axis = 1)\n",
    "df['text_a_gender_m'] = df.apply(lambda x: swap_address(x['text_m_f'], x['address_f']), axis = 1)\n",
    "#swap names and addresses (use columns with swapped names as a starting point)\n",
    "df['text_n_a_f'] = df.apply(lambda x: swap_address(x['text_n_f'], x['address_m']), axis = 1)\n",
    "df['text_n_a_m'] = df.apply(lambda x: swap_address(x['text_n_m'], x['address_f']), axis = 1)\n",
    "df['text_n_a_gender_f'] = df.apply(lambda x: swap_address(x['text_n_gender_f'], x['address_m']), axis = 1)\n",
    "df['text_n_a_gender_m'] = df.apply(lambda x: swap_address(x['text_n_gender_m'], x['address_f']), axis = 1)\n",
    "\n",
    "#remove labels\n",
    "text_cols = list(filter(lambda x: x.startswith('text'), df.columns))\n",
    "\n",
    "for col in text_cols:\n",
    "    df[col] = df.apply(lambda x: re.sub('<[^>]*>', '', x[col]), axis = 1)\n",
    "\n",
    "\n",
    "# separate into different dataframes\n",
    "f = rename_col_t_r(df[['text_f', 'thirty_day_readmission_f']].copy())\n",
    "f_m_address = rename_col_t_r(df[['text_a_f', 'thirty_day_readmission_f']].copy())\n",
    "f_m_name = rename_col_t_r(df[['text_n_f', 'thirty_day_readmission_f']].copy())\n",
    "f_m_name_address = rename_col_t_r(df[['text_n_a_f', 'thirty_day_readmission_f']].copy())\n",
    "f_m_gender = rename_col_t_r(df[['text_f_m', 'thirty_day_readmission_f']].copy())\n",
    "f_m_gender_address = rename_col_t_r(df[['text_a_gender_f', 'thirty_day_readmission_f']].copy())\n",
    "f_m_gender_name = rename_col_t_r(df[['text_n_gender_f', 'thirty_day_readmission_f']].copy())\n",
    "f_m_gender_name_address = rename_col_t_r(df[['text_n_a_gender_f', 'thirty_day_readmission_f']].copy())\n",
    "\n",
    "m = rename_col_t_r(df[['text_m', 'thirty_day_readmission_m']].copy())\n",
    "m_f_address = rename_col_t_r(df[['text_a_m', 'thirty_day_readmission_m']].copy())\n",
    "m_f_name = rename_col_t_r(df[['text_n_m', 'thirty_day_readmission_m']].copy())\n",
    "m_f_name_address = rename_col_t_r(df[['text_n_a_m', 'thirty_day_readmission_m']].copy())\n",
    "m_f_gender = rename_col_t_r(df[['text_m_f', 'thirty_day_readmission_m']].copy())\n",
    "m_f_gender_address = rename_col_t_r(df[['text_a_gender_m', 'thirty_day_readmission_m']].copy())\n",
    "m_f_gender_name = rename_col_t_r(df[['text_n_gender_m', 'thirty_day_readmission_m']].copy())\n",
    "m_f_gender_name_address = rename_col_t_r(df[['text_n_a_gender_m', 'thirty_day_readmission_m']].copy())\n",
    "\n",
    "\n",
    "groups = [('f', f),\n",
    "            ('f_m_address', f_m_address),\n",
    "            ('f_m_name', f_m_name),\n",
    "            ('f_m_name_address', f_m_name_address),\n",
    "            ('f_m_gender', f_m_gender),\n",
    "            ('f_m_gender_address', f_m_gender_address),\n",
    "            ('f_m_gender_name', f_m_gender_name),\n",
    "            ('f_m_gender_name_address', f_m_gender_name_address),\n",
    "            ('m', m),\n",
    "            ('m_f_address', m_f_address),\n",
    "            ('m_f_name', m_f_name),\n",
    "            ('m_f_name_address', m_f_name_address),\n",
    "            ('m_f_gender', m_f_gender),\n",
    "            ('m_f_gender_address', m_f_gender_address),\n",
    "            ('m_f_gender_name', m_f_gender_name),\n",
    "            ('m_f_gender_name_address', m_f_gender_name_address)]\n",
    "\n",
    "\n",
    "gender_test_group = {}\n",
    "\n",
    "for name, group in groups:\n",
    "\n",
    "    #save in a Test files dictionary\n",
    "    gender_test_group[name] = group.reset_index(drop = True)\n",
    "\n",
    "    #export to csv\n",
    "    path = f'readmission_prediction/gender_swapping/data/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    group.to_csv(path+f'{name}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30063c6-e78b-4fd6-87bf-b1bd66afd319",
   "metadata": {},
   "source": [
    "## Notes with different races (/grouped_anonymized/race_swapping)\n",
    "- leave out explicit race info, swap names and/or addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08a11e-ee04-43a0-9ec0-9e306169df99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_notes = test_notes.copy()\n",
    "\n",
    "#prepare the notes\n",
    "new_notes = swap_in(new_notes, race = False)\n",
    "\n",
    "#get additional info for every note\n",
    "notes_df = get_hadm_id(new_notes)\n",
    "notes_df = pd.merge(notes_df, note_info[['hadm_id', 'gender', 'race_abbrev', 'actual_age', \n",
    "                                         'name', 'address', 'thirty_day_readmission']], on = 'hadm_id')\n",
    "\n",
    "#loop through all possible race combinations\n",
    "races = note_info['race_abbrev'].unique()\n",
    "\n",
    "#save all test groups for sanity checks\n",
    "race_test_group = {}\n",
    "\n",
    "for baseline_race in races:\n",
    "\n",
    "    #baseline notes with specific race, split by gender\n",
    "    #rank by age\n",
    "    base_f = notes_df[(notes_df['race_abbrev'] == baseline_race) & (notes_df['gender'] == 'F')].copy()\n",
    "    base_f['age_rank'] = base_f['actual_age'].rank(method = 'first')\n",
    "    \n",
    "    if baseline_race != 'HL_CO':\n",
    "        base_m = notes_df[(notes_df['race_abbrev'] == baseline_race) & (notes_df['gender'] == 'M')].copy()\n",
    "        base_m['age_rank'] = base_m['actual_age'].rank(method = 'first')\n",
    "    \n",
    "    \n",
    "    for new_race in races:\n",
    "        \n",
    "        if baseline_race == new_race:\n",
    "            \n",
    "            #filter for that race\n",
    "            group = notes_df[notes_df['race_abbrev'] == baseline_race].copy()\n",
    "            \n",
    "            #remove labels\n",
    "            group['text'] = group.apply(lambda x: re.sub('<[^>]*>', '', x['text']), axis = 1)\n",
    "\n",
    "            group = group[['text','thirty_day_readmission']]\n",
    "\n",
    "            #save in a Test files dictionary\n",
    "            race_test_group[baseline_race] = group.reset_index(drop = True)\n",
    "        \n",
    "            #export to csv\n",
    "            path = f'readmission_prediction/race_swapping/data/'\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            group.to_csv(path+f'{baseline_race}.csv', index = False)\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            #baseline notes with specific race, split by gender\n",
    "            new_f = notes_df[(notes_df['race_abbrev'] == new_race) & (notes_df['gender'] == 'F')].copy()\n",
    "            \n",
    "            #rank by age\n",
    "            new_f['age_rank'] = new_f['actual_age'].rank(method = 'first')\n",
    "            \n",
    "            #merge with baseline notes\n",
    "            f = pd.merge(base_f, new_f, on = 'age_rank', suffixes = ['', '_new'], validate = 'one_to_one')\n",
    "\n",
    "            #swap name and/or address of the new race into the baseline race\n",
    "            f_name = f.copy()\n",
    "            f_name['text'] = f_name.apply(lambda x: swap_name(x['text'], x['name_new']), axis = 1)\n",
    "            f_address = f.copy()\n",
    "            f_address['text'] = f_address.apply(lambda x: swap_address(x['text'], x['address_new']), axis = 1)\n",
    "            f_name_address = f_name.copy()\n",
    "            f_name_address['text'] = f_name_address.apply(lambda x: swap_address(x['text'], x['address_new']), axis = 1)\n",
    "\n",
    "            #reduce dataframe-columns\n",
    "            f_name = f_name[['text', 'thirty_day_readmission']]\n",
    "            f_name_address = f_name_address[['text', 'thirty_day_readmission']]\n",
    "            f_address = f_address[['text', 'thirty_day_readmission']]\n",
    "\n",
    "\n",
    "            \n",
    "            #do everything again for the male subgroup, if it exists\n",
    "            if new_race != 'HL_CO':\n",
    "                new_m = notes_df[(notes_df['race_abbrev'] == new_race) & (notes_df['gender'] == 'M')].copy()\n",
    "                new_m['age_rank'] = new_m['actual_age'].rank(method = 'first')\n",
    "                m = pd.merge(base_m, new_m, on = 'age_rank', suffixes = ['', '_new'], validate = 'one_to_one')\n",
    "                m_name = m.copy()\n",
    "                m_name['text'] = m_name.apply(lambda x: swap_name(x['text'], x['name_new']), axis = 1)\n",
    "                m_address = m.copy()\n",
    "                m_address['text'] = m_address.apply(lambda x: swap_address(x['text'], x['address_new']), axis = 1)\n",
    "                m_name_address = m_name.copy()\n",
    "                m_name_address['text'] = m_name_address.apply(lambda x: swap_address(x['text'], x['address_new']), axis = 1)\n",
    "                m_name = m_name[['text', 'thirty_day_readmission']]\n",
    "                m_name_address = m_name_address[['text', 'thirty_day_readmission']]\n",
    "                m_address = m_address[['text', 'thirty_day_readmission']]\n",
    "\n",
    "                #concat male and female group\n",
    "                name_df = pd.concat([f_name, m_name])\n",
    "                address_df = pd.concat([f_address, m_address])\n",
    "                name_address_df = pd.concat([f_name_address, m_name_address])\n",
    "\n",
    "            else:\n",
    "                name_df = f_name\n",
    "                address_df = f_address\n",
    "                name_address_df = f_name_address\n",
    "            \n",
    "\n",
    "            #remove labels\n",
    "            name_df['text'] = name_df.apply(lambda x: re.sub('<[^>]*>', '', x['text']), axis = 1)\n",
    "            address_df['text'] = address_df.apply(lambda x: re.sub('<[^>]*>', '', x['text']), axis = 1)\n",
    "            name_address_df['text'] = name_address_df.apply(lambda x: re.sub('<[^>]*>', '', x['text']), axis = 1)\n",
    "\n",
    "            groups = [(f'{baseline_race}_to_{new_race}_name', name_df),\n",
    "                        (f'{baseline_race}_to_{new_race}_address', address_df),\n",
    "                        (f'{baseline_race}_to_{new_race}_name_address', name_address_df)]\n",
    "\n",
    "            for name, group in groups:\n",
    "\n",
    "                #save in a Test files dictionary\n",
    "                race_test_group[name] = group.reset_index(drop = True)\n",
    "            \n",
    "                #export to csv\n",
    "                path = f'readmission_prediction/race_swapping/data/'\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                group.to_csv(path+f'{name}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89549ec-9c17-410d-971e-8b25140c0aa0",
   "metadata": {},
   "source": [
    "Swap in race explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd1872a-af7a-401d-8ee1-b17f282d8bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_notes = test_notes.copy()\n",
    "\n",
    "#prepare the notes\n",
    "new_notes = add_race(new_notes)\n",
    "new_notes = swap_in(new_notes)\n",
    "\n",
    "#get additional info for every note\n",
    "notes_df = get_hadm_id(new_notes)\n",
    "notes_df = pd.merge(notes_df, note_info[['hadm_id', 'gender', 'race_abbrev', 'actual_age', \n",
    "                                         'name', 'address', 'thirty_day_readmission']], on = 'hadm_id')\n",
    "\n",
    "#loop through all possible race combinations\n",
    "races = note_info['race_abbrev'].unique()\n",
    "\n",
    "#save all test groups for sanity checks\n",
    "race_test_group = {}\n",
    "\n",
    "for baseline_race in races:\n",
    "  \n",
    "    for new_race in races:\n",
    "\n",
    "        #filter for that race\n",
    "        group = notes_df[notes_df['race_abbrev'] == baseline_race].copy()\n",
    "\n",
    "        if baseline_race != new_race:\n",
    "            group['text'] = group.apply(lambda x: swap_race(x['text'], new_race), axis = 1)\n",
    "\n",
    "\n",
    "        #remove labels\n",
    "        group['text'] = group.apply(lambda x: re.sub('<[^>]*>', '', x['text']), axis = 1)\n",
    "\n",
    "        group = group[['text','thirty_day_readmission']]\n",
    "\n",
    "        #save in a Test files dictionary\n",
    "        race_test_group[baseline_race] = group.reset_index(drop = True)\n",
    "    \n",
    "        #export to csv\n",
    "        path = f'readmission_prediction/race_swapping/data/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        if baseline_race == new_race:\n",
    "            group.to_csv(path+f'{baseline_race}_race.csv', index = False)\n",
    "        else:\n",
    "            group.to_csv(path+f'{baseline_race}_to_{new_race}_race.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d65f7-8ffb-4f7a-bb37-cc7b0af8dd90",
   "metadata": {},
   "source": [
    "## Create notes with swapped age in each subgroup (/grouped_anonymized/age_swapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68031fb-be3a-488f-a8bd-0d0025ae4335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#swap in personal info\n",
    "new_notes = test_notes.copy()\n",
    "new_notes = swap_in(new_notes)\n",
    "\n",
    "#get additional info in separate columns\n",
    "notes_df = get_hadm_id(new_notes)\n",
    "notes_df = pd.merge(note_info, notes_df, on = 'hadm_id')\n",
    "\n",
    "#group by race-gender-subgroup \n",
    "#rank by age in each subgroup\n",
    "notes_df['age_rank'] = notes_df.groupby('abbrev')['actual_age'].transform(lambda x: x.rank(method = 'first'))\n",
    "notes_df['age_rank_reverse'] = notes_df.groupby('abbrev')['actual_age'].transform(lambda x: x.rank(method = 'first', ascending = False))\n",
    "\n",
    "\n",
    "#loop through each race-gender-subgroup\n",
    "subgroups = note_info['abbrev'].unique()\n",
    "\n",
    "age_cols = ['hadm_id_y', 'thirty_day_readmission_y', 'text_y', 'name_y', 'address_y', 'actual_age_y', 'dob_y',\n",
    "       'hadm_id_o','thirty_day_readmission_o', 'text_o', 'name_o', 'address_o', 'actual_age_o', 'dob_o',\n",
    "       'text_o_y_age', 'text_o_y_name', 'text_o_y_address',\n",
    "       'text_o_y_age_name', 'text_o_y_age_address', 'text_o_y_name_address',\n",
    "       'text_o_y_age_name_address', 'text_y_o_age', 'text_y_o_name',\n",
    "       'text_y_o_address', 'text_y_o_age_name', 'text_y_o_age_address',\n",
    "       'text_y_o_name_address', 'text_y_o_age_name_address']\n",
    "complete_age = pd.DataFrame(columns = age_cols)\n",
    "\n",
    "for subgroup in subgroups:\n",
    "    \n",
    "    #select rows belonging to that subgroup\n",
    "    subgroup_df = notes_df[notes_df['abbrev'] == subgroup]\n",
    "\n",
    "    #filter oldest and youngest quarter\n",
    "    cols = ['age_rank','hadm_id', 'text', 'name', 'address', 'actual_age', 'dob', 'thirty_day_readmission']\n",
    "    young = subgroup_df[subgroup_df['age_rank']<=12][cols]\n",
    "    old = subgroup_df[subgroup_df['age_rank']>38][cols]\n",
    "\n",
    "    #adjust old age_rank\n",
    "    old['age_rank'] = old['age_rank']-38\n",
    "\n",
    "    #merge old and young \n",
    "    merged = pd.merge(young, old, on = 'age_rank', suffixes = ['_y', '_o'])\n",
    "    merged.drop('age_rank', axis = 1, inplace = True)\n",
    "\n",
    "    \n",
    "    merged['text_o_y_age'] = merged.apply(lambda x: swap_age(x['text_o'], age = x['actual_age_y'], dob = x['dob_y']), axis = 1)\n",
    "    merged['text_o_y_name'] = merged.apply(lambda x: swap_name(x['text_o'], x['name_y']), axis = 1)\n",
    "    merged['text_o_y_address'] = merged.apply(lambda x: swap_address(x['text_o'], x['address_y']), axis = 1)\n",
    "    merged['text_o_y_age_name'] = merged.apply(lambda x: swap_name(x['text_o_y_age'], x['name_y']), axis = 1)\n",
    "    merged['text_o_y_age_address'] = merged.apply(lambda x: swap_address(x['text_o_y_age'], x['address_y']), axis = 1)\n",
    "    merged['text_o_y_name_address'] = merged.apply(lambda x: swap_address(x['text_o_y_name'], x['address_y']), axis = 1)\n",
    "    merged['text_o_y_age_name_address'] = merged.apply(lambda x: swap_address(x['text_o_y_age_name'], x['address_y']), axis = 1)\n",
    "\n",
    "    merged['text_y_o_age'] = merged.apply(lambda x: swap_age(x['text_y'], age = x['actual_age_o'], dob = x['dob_o']), axis = 1)\n",
    "    merged['text_y_o_name'] = merged.apply(lambda x: swap_name(x['text_y'], x['name_o']), axis = 1)\n",
    "    merged['text_y_o_address'] = merged.apply(lambda x: swap_address(x['text_y'], x['address_o']), axis = 1)\n",
    "    merged['text_y_o_age_name'] = merged.apply(lambda x: swap_name(x['text_y_o_age'], x['name_o']), axis = 1)\n",
    "    merged['text_y_o_age_address'] = merged.apply(lambda x: swap_address(x['text_y_o_age'], x['address_o']), axis = 1)\n",
    "    merged['text_y_o_name_address'] = merged.apply(lambda x: swap_address(x['text_y_o_name'], x['address_o']), axis = 1)\n",
    "    merged['text_y_o_age_name_address'] = merged.apply(lambda x: swap_address(x['text_y_o_age_name'], x['address_o']), axis = 1)\n",
    "\n",
    "    #remove labels\n",
    "    text_cols = list(filter(lambda x: x.startswith('text'), merged.columns))\n",
    "    for col in text_cols:\n",
    "        merged[col] = merged.apply(lambda x: re.sub('<[^>]*>', '', x[col]), axis = 1)\n",
    "        \n",
    "    complete_age = pd.concat([complete_age, merged])\n",
    "    \n",
    "\n",
    "groups = [\n",
    "    ('old', rename_col_t_r(complete_age[['text_o', 'thirty_day_readmission_o']])),\n",
    "    ('old_young_age', rename_col_t_r(complete_age[['text_o_y_age', 'thirty_day_readmission_o']])),\n",
    "    ('old_young_name', rename_col_t_r(complete_age[['text_o_y_name', 'thirty_day_readmission_o']])),\n",
    "    ('old_young_address', rename_col_t_r(complete_age[['text_o_y_address', 'thirty_day_readmission_o']])),\n",
    "    ('old_young_age_name', rename_col_t_r(complete_age[['text_o_y_age_name', 'thirty_day_readmission_o']])),\n",
    "    ('old_young_age_address', rename_col_t_r(complete_age[['text_o_y_age_address', 'thirty_day_readmission_o']])),\n",
    "    ('old_young_name_address', rename_col_t_r(complete_age[['text_o_y_name_address', 'thirty_day_readmission_o']])),\n",
    "    ('old_young_age_name_address', rename_col_t_r(complete_age[['text_o_y_age_name_address', 'thirty_day_readmission_o']])),\n",
    "    ('young', rename_col_t_r(complete_age[['text_y', 'thirty_day_readmission_y']])),\n",
    "    ('young_old_age', rename_col_t_r(complete_age[['text_y_o_age', 'thirty_day_readmission_y']])),\n",
    "    ('young_old_name', rename_col_t_r(complete_age[['text_y_o_name', 'thirty_day_readmission_y']])),\n",
    "    ('young_old_address', rename_col_t_r(complete_age[['text_y_o_address', 'thirty_day_readmission_y']])),\n",
    "    ('young_old_age_name', rename_col_t_r(complete_age[['text_y_o_age_name', 'thirty_day_readmission_y']])),\n",
    "    ('young_old_age_address', rename_col_t_r(complete_age[['text_y_o_age_address', 'thirty_day_readmission_y']])),\n",
    "    ('young_old_name_address', rename_col_t_r(complete_age[['text_y_o_name_address', 'thirty_day_readmission_y']])),\n",
    "    ('young_old_age_name_address', rename_col_t_r(complete_age[['text_y_o_age_name_address', 'thirty_day_readmission_y']]))\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "age_test_group = {}\n",
    "\n",
    "for name, group in groups:\n",
    "\n",
    "    #save in a Test files dictionary\n",
    "    age_test_group[name] = group.reset_index(drop = True)\n",
    "\n",
    "    #export to csv\n",
    "    path = f'readmission_prediction/age_swapping/data/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    group.to_csv(path+f'{name}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca431a8-8653-4440-bd11-0675e1e84403",
   "metadata": {},
   "source": [
    "## Create notes with shifted age (/grouped_anonymized/age_shifting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d96df5b-4657-472d-8385-90be7e86bb89",
   "metadata": {},
   "source": [
    "#### Filter for notes that allow a plausible age shift (inside the age range of the dataset)\n",
    "- only shift to ages the model has seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c82e2-6246-492c-bfd2-030ccd154dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_info_test['actual_age'].quantile([0,0.25,0.5,0.75,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051c66e-340f-458b-b60d-bf3a0c1c6609",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_info_train['actual_age'].quantile([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ed3cae-1663-42de-843d-e2b212a05cbb",
   "metadata": {},
   "source": [
    "#### Create notes with a shifted age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec04d9b-b193-4d79-91d3-711026d3e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_shift_notes = test_notes.copy()\n",
    "age_shift_notes = swap_in(age_shift_notes) \n",
    "age_shift_notes = get_hadm_id(age_shift_notes)\n",
    "\n",
    "age_shift_info = note_info_test[(note_info_test['actual_age']>=39) & (note_info_test['actual_age']<=78)]\n",
    "\n",
    "age_shift = pd.merge(age_shift_notes, age_shift_info, on = 'hadm_id', how = 'inner')\n",
    "\n",
    "#shift age in the text\n",
    "age_shift['text_plus_10'] = age_shift.apply(lambda x: swap_age(x['text'], age = x['actual_age']+10, dob = x['dob']-10), axis = 1)\n",
    "age_shift['text_plus_20'] = age_shift.apply(lambda x: swap_age(x['text'], age = x['actual_age']+20, dob = x['dob']-20), axis = 1)\n",
    "age_shift['text_minus_10'] = age_shift.apply(lambda x: swap_age(x['text'], age = x['actual_age']-10, dob = x['dob']+10), axis = 1)\n",
    "age_shift['text_minus_20'] = age_shift.apply(lambda x: swap_age(x['text'], age = x['actual_age']-20, dob = x['dob']+20), axis = 1)\n",
    "\n",
    "#remove labels\n",
    "text_cols = list(filter(lambda x: x.startswith('text'), age_shift.columns))\n",
    "for col in text_cols:\n",
    "    age_shift[col] = age_shift.apply(lambda x: re.sub('<[^>]*>', '', x[col]), axis = 1)\n",
    "\n",
    "\n",
    "groups = [('age', age_shift[['text', 'thirty_day_readmission']]),\n",
    "            ('age_plus_10', rename_col_t_r(age_shift[['text_plus_10', 'thirty_day_readmission']])),\n",
    "            ('age_plus_20', rename_col_t_r(age_shift[['text_plus_20', 'thirty_day_readmission']])),\n",
    "            ('age_minus_10', rename_col_t_r(age_shift[['text_minus_10', 'thirty_day_readmission']])),\n",
    "            ('age_minus_20', rename_col_t_r(age_shift[['text_minus_20', 'thirty_day_readmission']]))]\n",
    "          \n",
    "\n",
    "\n",
    "age_shift_test_group = {}\n",
    "\n",
    "for name, group in groups:\n",
    "\n",
    "    #save in a Test files dictionary\n",
    "    age_shift_test_group[name] = group.reset_index(drop = True)\n",
    "\n",
    "    #export to csv\n",
    "    path = f'readmission_prediction/age_shifting/data/'\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    group.to_csv(path+f'{name}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703f2c25-ff41-49e7-b71e-0b4ebf0dd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_test_group['old'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c619f056-37eb-4037-bcce-df214f9d7369",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_info_test[(note_info_test['actual_age']<39) | (note_info_test['actual_age']>78)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb174d-4050-484c-8c45-ee65c342382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_shift_info.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda_envs-gpulab-2025-1] *",
   "language": "python",
   "name": "conda-env-conda_envs-gpulab-2025-1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
